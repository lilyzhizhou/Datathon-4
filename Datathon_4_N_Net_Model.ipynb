{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb2L72WcQslszId87kfDJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilyzhizhou/Datathon-4/blob/main/Datathon_4_N_Net_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ccZFA5Y-CWoC"
      },
      "outputs": [],
      "source": [
        "# Loading Packages\n",
        "# importing torch as t\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch as t\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, relu, tanh\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from torch.nn import Tanh, Linear, Sequential, Sigmoid, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agrqcpgAPLSf",
        "outputId": "b4879751-6918-49d0-ae69-aad3b6eb2b8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning /Datathon #4/data_clean.csv')\n",
        "\n",
        "data = data.drop('Unnamed: 0',axis = 1)\n",
        "\n",
        "# drop apache vars\n",
        "data = data.drop(['apache_4a_icu_death_prob','apache_2_diagnosis','apache_3j_diagnosis'],axis = 1)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lrIn8zmpPMr4",
        "outputId": "711bf976-c727-4642-e188-8cb95411d01d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   hospital_death   age  gender  h1_diasbp_noninvasive_max  \\\n",
              "0               0  25.0     1.0                       88.0   \n",
              "1               0  67.0     0.0                       89.0   \n",
              "2               0  70.0     0.0                       74.0   \n",
              "3               0  50.0     0.0                       83.0   \n",
              "4               0  48.0     0.0                      123.0   \n",
              "\n",
              "   h1_diasbp_noninvasive_min  h1_heartrate_max  h1_heartrate_min  \\\n",
              "0                       58.0              96.0              78.0   \n",
              "1                       89.0              83.0              83.0   \n",
              "2                       55.0             118.0             114.0   \n",
              "3                       61.0              96.0              60.0   \n",
              "4                       69.0              92.0              66.0   \n",
              "\n",
              "   h1_mbp_noninvasive_max  h1_mbp_noninvasive_min  h1_resprate_max  \\\n",
              "0                    91.0                    83.0             20.0   \n",
              "1                   111.0                   111.0             12.0   \n",
              "2                    88.0                    60.0             28.0   \n",
              "3                   101.0                    77.0             29.0   \n",
              "4                   140.0                   112.0             24.0   \n",
              "\n",
              "   h1_resprate_min  h1_spo2_max  h1_spo2_min  h1_sysbp_noninvasive_max  \\\n",
              "0             16.0         98.0         91.0                     148.0   \n",
              "1             12.0         97.0         97.0                     143.0   \n",
              "2             26.0         96.0         92.0                     119.0   \n",
              "3             17.0        100.0         96.0                     135.0   \n",
              "4             16.0         99.0         98.0                     163.0   \n",
              "\n",
              "   h1_sysbp_noninvasive_min  h1_temp_max  h1_temp_min  gcs_eyes_apache  \\\n",
              "0                     124.0         36.7         36.7              3.0   \n",
              "1                     143.0         36.7         36.7              4.0   \n",
              "2                     106.0         38.5         38.5              4.0   \n",
              "3                     103.0         36.9         36.9              4.0   \n",
              "4                     111.0         36.7         36.6              4.0   \n",
              "\n",
              "   gcs_motor_apache  gcs_verbal_apache  \n",
              "0               6.0                5.0  \n",
              "1               6.0                5.0  \n",
              "2               6.0                5.0  \n",
              "3               6.0                5.0  \n",
              "4               6.0                5.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bdaa736-3bcf-445d-93ee-e8aad674f2de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hospital_death</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>h1_diasbp_noninvasive_max</th>\n",
              "      <th>h1_diasbp_noninvasive_min</th>\n",
              "      <th>h1_heartrate_max</th>\n",
              "      <th>h1_heartrate_min</th>\n",
              "      <th>h1_mbp_noninvasive_max</th>\n",
              "      <th>h1_mbp_noninvasive_min</th>\n",
              "      <th>h1_resprate_max</th>\n",
              "      <th>h1_resprate_min</th>\n",
              "      <th>h1_spo2_max</th>\n",
              "      <th>h1_spo2_min</th>\n",
              "      <th>h1_sysbp_noninvasive_max</th>\n",
              "      <th>h1_sysbp_noninvasive_min</th>\n",
              "      <th>h1_temp_max</th>\n",
              "      <th>h1_temp_min</th>\n",
              "      <th>gcs_eyes_apache</th>\n",
              "      <th>gcs_motor_apache</th>\n",
              "      <th>gcs_verbal_apache</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>36.7</td>\n",
              "      <td>36.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>36.7</td>\n",
              "      <td>36.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>38.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>36.9</td>\n",
              "      <td>36.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>36.7</td>\n",
              "      <td>36.6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bdaa736-3bcf-445d-93ee-e8aad674f2de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bdaa736-3bcf-445d-93ee-e8aad674f2de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bdaa736-3bcf-445d-93ee-e8aad674f2de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-211d4b1d-c0c1-4876-badd-f97ed57642de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-211d4b1d-c0c1-4876-badd-f97ed57642de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-211d4b1d-c0c1-4876-badd-f97ed57642de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for death imbalance\n",
        "import plotly.express as px\n",
        "\n",
        "# Compute the count of each class in the 'target' column\n",
        "counts = data_test['hospital_death'].value_counts()\n",
        "\n",
        "# Define colors for the pie chart sections\n",
        "colors = ['#a3416c', '#ebc898']\n",
        "\n",
        "# Construct a pie chart with plotly\n",
        "# 'names' are the class labels, and 'values' are the counts for each class\n",
        "fig = px.pie(\n",
        "    names=counts.index,\n",
        "    values=counts.values,\n",
        "    hole=0.5,  # creates a donut-styled pie chart\n",
        "    title='Distribution of death',\n",
        "    color_discrete_sequence=colors\n",
        ")\n",
        "\n",
        "# Update the layout of the pie chart for better presentation and clarity\n",
        "fig.update_layout(\n",
        "    margin=dict(t=50, b=0, l=0, r=0),\n",
        "    legend=dict(\n",
        "        orientation=\"v\",\n",
        "        yanchor=\"top\",\n",
        "        y=0.5,\n",
        "        xanchor=\"left\",\n",
        "        x=1.05,\n",
        "        title='target'\n",
        "    ),\n",
        "    title=dict(\n",
        "        text='Distribution of Classes in death',\n",
        "        x=0.45,\n",
        "        xanchor='center',\n",
        "        y=0.95,\n",
        "        yanchor='top',\n",
        "        font=dict(size=16)\n",
        "    ),\n",
        "    width=500,\n",
        "    height=350\n",
        ")\n",
        "\n",
        "# Display the pie chart\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_1fnGlydQxnu",
        "outputId": "034311cc-da26-4e31-ac48-b0c0d2089078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b33c3659-58fa-4e7d-9552-dfeed2a844d7\" class=\"plotly-graph-div\" style=\"height:350px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b33c3659-58fa-4e7d-9552-dfeed2a844d7\")) {                    Plotly.newPlot(                        \"b33c3659-58fa-4e7d-9552-dfeed2a844d7\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hole\":0.5,\"hovertemplate\":\"label=%{label}\\u003cbr\\u003evalue=%{value}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[0,1],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[914,86],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"v\",\"yanchor\":\"top\",\"y\":0.5,\"xanchor\":\"left\",\"x\":1.05,\"title\":{\"text\":\"target\"}},\"title\":{\"text\":\"Distribution of Classes in death\",\"font\":{\"size\":16},\"x\":0.45,\"xanchor\":\"center\",\"y\":0.95,\"yanchor\":\"top\"},\"piecolorway\":[\"#a3416c\",\"#ebc898\"],\"margin\":{\"t\":50,\"b\":0,\"l\":0,\"r\":0},\"width\":500,\"height\":350},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b33c3659-58fa-4e7d-9552-dfeed2a844d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data into Training and Testing\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eGAQ9svCTt-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample 70% of the data for training\n",
        "train_data = data.sample(frac = .7, random_state=10)\n",
        "\n",
        "# Use the remaining 30% for testing\n",
        "test_data = data.drop(train_data.index)\n",
        "\n",
        "# Check the mean of the 'hospital_death' column in both training and testing data\n",
        "print('train', train_data['hospital_death'].mean())\n",
        "print('test', test_data['hospital_death'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjfWWRvkR3MC",
        "outputId": "e75605de-3160-48eb-b71e-105b79554181"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0.08613282928086606\n",
            "test 0.08089414595028067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "\n",
        "# Extract the 'hospital_death' column as the target variable for training and testing\n",
        "Y_train = train_data['hospital_death'].to_numpy()\n",
        "Y_test = test_data['hospital_death'].to_numpy()\n",
        "\n",
        "# Extract the features (excluding 'hospital_death') for training and testing\n",
        "X_train = train_data.drop('hospital_death', axis=1).to_numpy()\n",
        "X_test = test_data.drop('hospital_death', axis=1).to_numpy()"
      ],
      "metadata": {
        "id": "cSi_CkAXSKIW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Data\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V887j0OWT9pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features to have zero mean and unit variance\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "ntKh2s3lI-aB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cNv-6QuLb0Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling using SMOTE\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "smote_nc = SMOTENC(categorical_features=[3], random_state=42)\n",
        "X_train_resampled, Y_train_resampled = smote_nc.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y_train_resampled == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(Y_train_resampled == 0)))"
      ],
      "metadata": {
        "id": "oXz0-VBza17i",
        "outputId": "7cf163b8-23fa-4f1c-de85-a43ef27569f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After OverSampling, counts of label '1': 21273\n",
            "After OverSampling, counts of label '0': 21273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing Neural Network Parameters in PyTorch"
      ],
      "metadata": {
        "id": "TgMhfJFZTHeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of neurons in the first and second hidden layers\n",
        "hidden_units_layer_1 = 5\n",
        "hidden_units_layer_2 = 5\n",
        "\n",
        "# FIRST LAYER: Define weights and biases for the first layer\n",
        "W1 = t.randn((19, hidden_units_layer_1), requires_grad=True)\n",
        "B1 = t.zeros((1, hidden_units_layer_1), requires_grad=True)\n",
        "\n",
        "# SECOND LAYER: Define weights and biases for the second layer\n",
        "W2 = t.randn((hidden_units_layer_1, hidden_units_layer_2), requires_grad=True)\n",
        "B2 = t.zeros((1, hidden_units_layer_2), requires_grad=True)\n",
        "\n",
        "# THIRD LAYER: Define weights and biases for the output layer\n",
        "W3 = t.randn((hidden_units_layer_2, 1), requires_grad=True)\n",
        "B3 = t.zeros((1, 1), requires_grad=True)"
      ],
      "metadata": {
        "id": "vDb3WfelTJ7k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the Forward Pass of a Neural Network in PyTorch"
      ],
      "metadata": {
        "id": "YI3FFMV_US6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the forward pass of the neural network\n",
        "def forward(input):\n",
        "    # First hidden layer with ReLU activation\n",
        "    out = relu(input @ W1 + B1)\n",
        "\n",
        "    # Second hidden layer with ReLU activation\n",
        "    out = relu(out @ W2 + B2)\n",
        "\n",
        "    # Output layer with sigmoid activation (since it's a binary classification problem)\n",
        "    out = sigmoid(out @ W3 + B3)\n",
        "    return out"
      ],
      "metadata": {
        "id": "3s0gwvDtUThN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Data and Training Utilities for Neural Network Training in PyTorch"
      ],
      "metadata": {
        "id": "3ykVNEOXZg6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the training data to PyTorch tensors\n",
        "X = t.Tensor(X_train).type(t.float32)\n",
        "Y = t.Tensor(Y_train).type(t.float32)\n",
        "\n",
        "# Create a dataset from tensors to be used with DataLoader\n",
        "train_dataset = TensorDataset(X, Y)\n",
        "\n",
        "# Define training hyperparameters\n",
        "epochs = 2000\n",
        "learning_rate = 0.01\n",
        "batch_size = 50\n",
        "\n",
        "# DataLoader provides batches of data for training\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the optimizer (Adam) and include all weights and biases\n",
        "optimizer = Adam([W1, B1, W2, B2, W3, B3], lr=learning_rate)\n",
        "\n",
        "# Define the loss function (Binary Cross-Entropy Loss)\n",
        "loss_fn = t.nn.BCELoss()"
      ],
      "metadata": {
        "id": "ceuWzhjLZjJe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop for a Neural Network in PyTorch"
      ],
      "metadata": {
        "id": "yzklLKidaqFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "\n",
        "# Train the model for a specified number of epochs\n",
        "for epoch in range(epochs):\n",
        "    # Reduce the learning rate every 500 epochs\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= .9\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    # Iterate over all batches of data\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = forward(X)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "\n",
        "        # Backward pass: Compute gradient and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Record the loss for this batch\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "  # Record the average loss for this epoch\n",
        "    train_loss_list.append(sum(per_epoch_loss_list) / len(per_epoch_loss_list))"
      ],
      "metadata": {
        "id": "co1v6ReTasib"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Training Loss Over Epochs with Matplotlib in Python"
      ],
      "metadata": {
        "id": "pYolGw81Jen6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss over epochs\n",
        "plt.plot([i for i in range(len(train_loss_list))], train_loss_list)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ],
      "metadata": {
        "id": "3aKAGfw8Jdji",
        "outputId": "2ac0de19-0232-49c5-88b6-96bb61460a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pt4p2BrS7Nh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Model Performance on Validation Data"
      ],
      "metadata": {
        "id": "aO6XXR8FJh_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model Performance on Validation Data\n",
        "\n",
        "# Disable gradient calculations for evaluation using t.no_grad()\n",
        "with t.no_grad():\n",
        "    # Prepare the validation data\n",
        "    X = t.Tensor(X_test).type(t.float32)  # Convert validation features to a PyTorch tensor\n",
        "    Y = t.Tensor(Y_test).type(t.float32)  # Convert validation labels to a PyTorch tensor\n",
        "\n",
        "    # Calculate predictions on the validation data\n",
        "    probs = forward(X)  # Pass validation data through the trained model\n",
        "    loss = loss_fn(probs.view(-1), Y)  # Compute the loss between predictions and actual labels\n",
        "\n",
        "    # Print the validation loss\n",
        "    print(loss.item())\n",
        "\n",
        "    # Now, evaluate the model on the training data\n",
        "    X = t.Tensor(X_train).type(t.float32)  # Convert training features to a PyTorch tensor\n",
        "    Y = t.Tensor(Y_train).type(t.float32)  # Convert training labels to a PyTorch tensor\n",
        "\n",
        "    # Calculate predictions on the training data\n",
        "    probs = forward(X)  # Pass training data through the trained model\n",
        "    loss = loss_fn(probs.view(-1), Y)  # Compute the loss between predictions and actual labels\n",
        "\n",
        "    # Print the training loss\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "id": "o2WFEy3jJjXq",
        "outputId": "b3a3702a-2833-4fe0-c7d1-e8ce09256d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21780796349048615\n",
            "0.21244768798351288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Test model have pretty similar loss functions\n",
        "- no sign of large amounts of overfitting"
      ],
      "metadata": {
        "id": "U1rqMnh6V77c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Regularized Training of a Neural Network in PyTorch"
      ],
      "metadata": {
        "id": "kZHuNTf2Jl65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import BCELoss"
      ],
      "metadata": {
        "id": "bZUbibH5pNum"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization\n",
        "\n",
        "# Define hyperparameters\n",
        "number_of_input_features = 19\n",
        "number_of_hidden_units = 5\n",
        "epochs = 1000\n",
        "learning_rate = 0.01\n",
        "batch_size = 50\n",
        "landa = 0.01  # Regularization term (lambda)\n",
        "dropout_probablity = 0.6  # Probability of dropping out a neuron in dropout layer"
      ],
      "metadata": {
        "id": "cUXcLLCRpRg2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "X_train_tensor = t.Tensor(X_train).type(t.float32)\n",
        "Y_train_tensor = t.Tensor(Y_train).type(t.float32)\n",
        "\n",
        "X_test_tensor = t.Tensor(X_test).type(t.float32)\n",
        "Y_test_tensor = t.Tensor(Y_test).type(t.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "RSh9ughfpbDM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model with regularization\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(number_of_input_features, number_of_hidden_units),\n",
        "    nn.ReLU(),\n",
        "    Dropout(dropout_probablity),\n",
        "    nn.Linear(number_of_hidden_units, 1),\n",
        "    nn.ReLU(),\n",
        "    nn.Sigmoid()  # Assuming binary classification for the output layer\n",
        ")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function with Binary Cross-Entropy Loss\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Lists to store training accuracy, validation accuracy, and training loss over epochs\n",
        "train_accuracy_list = []\n",
        "validation_accuracy_list = []\n",
        "train_loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= 0.9  # Learning rate scheduling\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = model(X)\n",
        "\n",
        "        # Adding regularization term for all parameters in the model\n",
        "        l2_term = sum([(w ** 2).sum() for w in model.parameters()])\n",
        "\n",
        "        # New loss is the old loss + regularization term\n",
        "        loss = loss_fn(probs.view(-1), Y) + landa * l2_term\n",
        "\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        # Backward pass: Compute gradient and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on training and validation data\n",
        "    with t.no_grad():\n",
        "        # Set the model in eval mode; some layers use this for certain calculations during training\n",
        "        model.eval()\n",
        "\n",
        "        # Calculate accuracy on train data\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Print accuracy for the current epoch\n",
        "        print(f'Epoch {epoch}/{epochs} ---> Train Accuracy: {train_accuracy}, Validation Accuracy: {validation_accuracy}')\n",
        "\n",
        "        # Set the model back to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Append accuracy values to lists\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "    # Calculate and append the average loss for the epoch\n",
        "    train_loss_list.append(sum(per_epoch_loss_list) / len(per_epoch_loss_list))"
      ],
      "metadata": {
        "id": "KnF6U2wSJm8-",
        "outputId": "cfecfa06-c740-4ebc-9cec-b3ea9a97be69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 1/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 2/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 3/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 4/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 5/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 6/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 7/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 8/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 9/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 10/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 11/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 12/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 13/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 14/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 15/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 16/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 17/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 18/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 19/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 20/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 21/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 22/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 23/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 24/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 25/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 26/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 27/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 28/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 29/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 30/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 31/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 32/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 33/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 34/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 35/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 36/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 37/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 38/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 39/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 40/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 41/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 42/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 43/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 44/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 45/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 46/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 47/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 48/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 49/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 50/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 51/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 52/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 53/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 54/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 55/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 56/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 57/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 58/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 59/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 60/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 61/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 62/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 63/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 64/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 65/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 66/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 67/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 68/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 69/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 70/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 71/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 72/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 73/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 74/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 75/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 76/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 77/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 78/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 79/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 80/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 81/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 82/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 83/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 84/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 85/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 86/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 87/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 88/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 89/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 90/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 91/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 92/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 93/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 94/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 95/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 96/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 97/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 98/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 99/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 100/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 101/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 102/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 103/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 104/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 105/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 106/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 107/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 108/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 109/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 110/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 111/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 112/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 113/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 114/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 115/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 116/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 117/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 118/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 119/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 120/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 121/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 122/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 123/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 124/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 125/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 126/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 127/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 128/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 129/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 130/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 131/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 132/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 133/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 134/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 135/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 136/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 137/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 138/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 139/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 140/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 141/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 142/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 143/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 144/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 145/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 146/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 147/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 148/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 149/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 150/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 151/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 152/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 153/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 154/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 155/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 156/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 157/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 158/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 159/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 160/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 161/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 162/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 163/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 164/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 165/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 166/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 167/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 168/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 169/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 170/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 171/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 172/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 173/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 174/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 175/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 176/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 177/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 178/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 179/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 180/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 181/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 182/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 183/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 184/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 185/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 186/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 187/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 188/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 189/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 190/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 191/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 192/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 193/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 194/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 195/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 196/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 197/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 198/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 199/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 200/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 201/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 202/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 203/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 204/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 205/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 206/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 207/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 208/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 209/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 210/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 211/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 212/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 213/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 214/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 215/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 216/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 217/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 218/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 219/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 220/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 221/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 222/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 223/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 224/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 225/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 226/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 227/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 228/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 229/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 230/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 231/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 232/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 233/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 234/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 235/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 236/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 237/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 238/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 239/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 240/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 241/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 242/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 243/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 244/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 245/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 246/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 247/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 248/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 249/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 250/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 251/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 252/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 253/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 254/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 255/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 256/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 257/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 258/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 259/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 260/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 261/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 262/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 263/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 264/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 265/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 266/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 267/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 268/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 269/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 270/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 271/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 272/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 273/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 274/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 275/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 276/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 277/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 278/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 279/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 280/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 281/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 282/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 283/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 284/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 285/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 286/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 287/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 288/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 289/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 290/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 291/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 292/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 293/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 294/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 295/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 296/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 297/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 298/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 299/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 300/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 301/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 302/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 303/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 304/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 305/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 306/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 307/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 308/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 309/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 310/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 311/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 312/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 313/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 314/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 315/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 316/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 317/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 318/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 319/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 320/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 321/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 322/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 323/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 324/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 325/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 326/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 327/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 328/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 329/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 330/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 331/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 332/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 333/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 334/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 335/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 336/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 337/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 338/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 339/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 340/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 341/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 342/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 343/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 344/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 345/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 346/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 347/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 348/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 349/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 350/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 351/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 352/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 353/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 354/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 355/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 356/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 357/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 358/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 359/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 360/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 361/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 362/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 363/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 364/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 365/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 366/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 367/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 368/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 369/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 370/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 371/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 372/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 373/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 374/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 375/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 376/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 377/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 378/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 379/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 380/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 381/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 382/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 383/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 384/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 385/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 386/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 387/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 388/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 389/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 390/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 391/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 392/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 393/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 394/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 395/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 396/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 397/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 398/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 399/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 400/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 401/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 402/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 403/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 404/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 405/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 406/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 407/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 408/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 409/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 410/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 411/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 412/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 413/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 414/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 415/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 416/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 417/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 418/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 419/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 420/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 421/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 422/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 423/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 424/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 425/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 426/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 427/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 428/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 429/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 430/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 431/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 432/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 433/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 434/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 435/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 436/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 437/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 438/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 439/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 440/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 441/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 442/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 443/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 444/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 445/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 446/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 447/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 448/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 449/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 450/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 451/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 452/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 453/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 454/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 455/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 456/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 457/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 458/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 459/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 460/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 461/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 462/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 463/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 464/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 465/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 466/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 467/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 468/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 469/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 470/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 471/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 472/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 473/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 474/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 475/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 476/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 477/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 478/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 479/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 480/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 481/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 482/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 483/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 484/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 485/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 486/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 487/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 488/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 489/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 490/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 491/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 492/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 493/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 494/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 495/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 496/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 497/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 498/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 499/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 500/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 501/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 502/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 503/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 504/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 505/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 506/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 507/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 508/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 509/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 510/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 511/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 512/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 513/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 514/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 515/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 516/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 517/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 518/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 519/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 520/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 521/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 522/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 523/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 524/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 525/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 526/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 527/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 528/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 529/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 530/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 531/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 532/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 533/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 534/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 535/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 536/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 537/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 538/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 539/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 540/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 541/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 542/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 543/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 544/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 545/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 546/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 547/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 548/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 549/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 550/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 551/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 552/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 553/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 554/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 555/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 556/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 557/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 558/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 559/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 560/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 561/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 562/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 563/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 564/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 565/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 566/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 567/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 568/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 569/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 570/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 571/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 572/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 573/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 574/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 575/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 576/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 577/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 578/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 579/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 580/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 581/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 582/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 583/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 584/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 585/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 586/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 587/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 588/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 589/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 590/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 591/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 592/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 593/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 594/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 595/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 596/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 597/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 598/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 599/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 600/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 601/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 602/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 603/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 604/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 605/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 606/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 607/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 608/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 609/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 610/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 611/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 612/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 613/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 614/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 615/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 616/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 617/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 618/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 619/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 620/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 621/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 622/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 623/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 624/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 625/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 626/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 627/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 628/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 629/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 630/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 631/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 632/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 633/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 634/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 635/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 636/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 637/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 638/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 639/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 640/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 641/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 642/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 643/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 644/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 645/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 646/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 647/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 648/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 649/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 650/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 651/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 652/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 653/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 654/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 655/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 656/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 657/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 658/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 659/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 660/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 661/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 662/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 663/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 664/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 665/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 666/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 667/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 668/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 669/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 670/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 671/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 672/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 673/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 674/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 675/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 676/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 677/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 678/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 679/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 680/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 681/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 682/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 683/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 684/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 685/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 686/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 687/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 688/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 689/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 690/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 691/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 692/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 693/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 694/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 695/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 696/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 697/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 698/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 699/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 700/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 701/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 702/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 703/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 704/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 705/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 706/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 707/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 708/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 709/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 710/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 711/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 712/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 713/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 714/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 715/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 716/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 717/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 718/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 719/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 720/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 721/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 722/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 723/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 724/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 725/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 726/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 727/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 728/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 729/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 730/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 731/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 732/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 733/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 734/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 735/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 736/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 737/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 738/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 739/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 740/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 741/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 742/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 743/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 744/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 745/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 746/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 747/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 748/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 749/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 750/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 751/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 752/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 753/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 754/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 755/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 756/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 757/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 758/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 759/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 760/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 761/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 762/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 763/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 764/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 765/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 766/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 767/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 768/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 769/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 770/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 771/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 772/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 773/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 774/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 775/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 776/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 777/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 778/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 779/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 780/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 781/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 782/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 783/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 784/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 785/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 786/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 787/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 788/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 789/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 790/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 791/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 792/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 793/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 794/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 795/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 796/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 797/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 798/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 799/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 800/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 801/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 802/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 803/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 804/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 805/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 806/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 807/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 808/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 809/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 810/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 811/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 812/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 813/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 814/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 815/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 816/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 817/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 818/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 819/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 820/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 821/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 822/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 823/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 824/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 825/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 826/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 827/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 828/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 829/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 830/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 831/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 832/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 833/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 834/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 835/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 836/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 837/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 838/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 839/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 840/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 841/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 842/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 843/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 844/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 845/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 846/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 847/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 848/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 849/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 850/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 851/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 852/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 853/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 854/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 855/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 856/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 857/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 858/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 859/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 860/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 861/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 862/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 863/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 864/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 865/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 866/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 867/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 868/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 869/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 870/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 871/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 872/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 873/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 874/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 875/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 876/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 877/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 878/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 879/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 880/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 881/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 882/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 883/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 884/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 885/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 886/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 887/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 888/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 889/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 890/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 891/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 892/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 893/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 894/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 895/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 896/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 897/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 898/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 899/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 900/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 901/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 902/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 903/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 904/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 905/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 906/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 907/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 908/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 909/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 910/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 911/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 912/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 913/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 914/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 915/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 916/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 917/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 918/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 919/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 920/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 921/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 922/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 923/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 924/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 925/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 926/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 927/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 928/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 929/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 930/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 931/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 932/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 933/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 934/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 935/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 936/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 937/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 938/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 939/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 940/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 941/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 942/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 943/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 944/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 945/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 946/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 947/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 948/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 949/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 950/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 951/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 952/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 953/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 954/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 955/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 956/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 957/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 958/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 959/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 960/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 961/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 962/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 963/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 964/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 965/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 966/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 967/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 968/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 969/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 970/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 971/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 972/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 973/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 974/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 975/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 976/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 977/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 978/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 979/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 980/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 981/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 982/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 983/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 984/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 985/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 986/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 987/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 988/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 989/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 990/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 991/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 992/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 993/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 994/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 995/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 996/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 997/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 998/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n",
            "Epoch 999/1000 ---> Train Accuracy: 0.08613283187150955, Validation Accuracy: 0.08089414238929749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation accuracy\n",
        "plt.plot([i for i in range(len(train_accuracy_list))], train_accuracy_list, label=\"train\")\n",
        "plt.plot([i for i in range(len(validation_accuracy_list))], validation_accuracy_list, label='validation')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dzHRNdFa6IAR",
        "outputId": "9529cdc1-30b0-4280-fd73-41aa87acc2cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}